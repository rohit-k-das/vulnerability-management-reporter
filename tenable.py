import requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
import datetime
import logging
import time
import concurrent.futures
from dataclasses import dataclass, field
from typing import List, Tuple, Dict
import re
import netaddr
import ConfigParser
import os

logger = logging.getLogger(__name__)
MAX_THREADS = 14  # Get max number of threads for multi-threading

# Read credentials for tenable
Config = ConfigParser.ConfigParser()
Config.read(os.path.join(os.path.abspath(os.path.dirname(__file__)),'settings.ini'))
tenable_client_id = Config.get('Settings', 'Tenable_Client_Id')
tenable_secret_id = Config.get('Settings', 'Tenable_Secret_Id')
tenable_gcp_tag = Config.get('Settings', 'Tenable_GCP_tag')
tenable_workstations_tag = Config.get('Settings', 'Tenable_Workstation_tag')
tenable_api = "https://cloud.tenable.com"


# Generate session with max of 3 retries and interval of 1 second
def session_generator() -> requests.sessions.Session:
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session


@dataclass  # A class to contain all the necessary fields to create report
class TenableVulnerability:
    plugin_name: str
    resolution: str
    additional_links: List[str]
    ip: str
    dns: str
    os: str
    cves: List[str]
    plugin_family: str
    exploit_available: bool
    cvss_score: float
    temporal_score: float
    vpr_score: float
    zone: str = field(init=False, default='')  # Critical/Non-critical Asset
    nessus_criticiality: str = field(init=False, default='')
    vulnerability_type: str = field(init=False, default='')
    actual_criticality: str = field(init=False, default='')
    host_risk: str = field(init=False, default='')
    platform: str = field(init=False, default='')

    def __post_init__(self):
        self.get_type()
        self.nessus_criticiality_insight()
        self.platform_based_on_os()
        self.modify_solution()

    def get_type(self):
        self.vulnerability_type = 'config'
        if self.plugin_family.lower() == 'Windows : Microsoft Bulletins'.lower():
            self.vulnerability_type = 'package'
        elif 'update ' in self.resolution.lower() or 'Update Set' in self.plugin_name or 'upgrade ' in self.resolution.lower() or 'MS KB' in self.plugin_name:
            self.vulnerability_type = 'package'
        elif 'Apply the client registry key workaround and the server registry key workaround suggested by Microsoft in the advisory.' == self.resolution:
            self.vulnerability_type = 'config'
        elif re.search('.* KB\d{3,} .*', self.resolution, flags=re.I) or 'patch' in self.resolution:
            self.vulnerability_type = 'package'

    def platform_based_on_os(self):
        if 'windows' in self.os.lower():
            self.platform = 'Windows'
        elif 'mac' in self.os.lower():
            self.platform = 'Mac'
        else:
            self.platform = 'Linux'

    def modify_solution(self):
        if self.vulnerability_type == 'package' and self.platform == 'Windows':
            if 'Microsoft has released the following security updates to address this issue:' in self.resolution or 'Apply the following security updates ' in self.resolution or 'Apply Service Stack ' in self.resolution or 'Microsoft has released KB' in self.resolution or 'Install Microsoft KB' in self.resolution:
                get_security_kb = re.findall(r"KB\d{4,}", self.resolution, flags=re.IGNORECASE)
                if not get_security_kb:
                    get_security_kb = re.findall(r"\d{4,}", self.resolution, flags=re.IGNORECASE)
                    get_security_kb = ["KB%s" % security_kb for security_kb in get_security_kb]
                if get_security_kb:
                    self.resolution = ','.join(get_security_kb).replace("'", '').replace('"', '').replace(' ', '')

            elif 'Apply '.lower() in self.resolution.lower():
                #
                get_security_kb = re.findall(r".*Security .* (KB\d{4,}) or Cumulative.*", self.resolution, flags=re.IGNORECASE)
                if not get_security_kb:
                    # Apply security update KB4022715 as well as refer to the KB article for additional information
                    get_security_kb = re.findall(r".*Security .* (KB\d{4,})", self.resolution, flags=re.IGNORECASE)

                if not get_security_kb:
                    # Apply Cumulative Update KB4056890 or KB4057142 as well as || Apply Cumulative Update KB4493509 *
                    get_security_kb = re.findall(r".*Cumulative .* (KB\d{4,})", self.resolution, flags=re.IGNORECASE)
                if get_security_kb:
                    self.resolution = ','.join(get_security_kb).replace("'", '').replace('"', '').replace(' ', '')

            elif 'MS' in self.plugin_name and 'KB' not in self.resolution:
                get_security_bulletin_number = re.findall(r"^MS\d{2,}-\d{3,}", self.plugin_name, flags=re.IGNORECASE)
                if len(get_security_bulletin_number) == 1:
                    year = get_security_bulletin_number[0].split('-')[0].replace('MS', '')
                    link = "https://docs.microsoft.com/en-us/security-updates/SecurityBulletins/20%s/%s" % (year, get_security_bulletin_number[0].lower())
                    self.resolution = link
            elif 'ADV' in self.plugin_name and ' KB' not in self.resolution:
                get_ADV = re.findall(r"^ADV\d{4,}", self.plugin_name, flags=re.IGNORECASE)
                if len(get_ADV) == 1:
                    ADV = get_ADV[0].split(':')[0]
                    link = "https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/%s" % ADV.upper()
                    self.resolution = link
            elif ('Microsoft has released a set of ' in self.resolution or 'Apply the appropriate patches according to the' in self.resolution or 'Microsoft has released security updates for ' in self.resolution or 'Microsoft has released a security update to ' in self.resolution):
                self.resolution = self.additional_links[0]

        elif self.vulnerability_type == 'package' and self.platform == 'Linux':
            """
            Modify Linux Solution that you want in the report as per your Linux box
            """
            if 'Update ' in self.resolution:
                self.resolution = 'yum update -y '
                for cve in self.cves:
                    self.resolution = '%s --cve %s ' % (self.resolution, cve)

    def nessus_criticiality_insight(self):
        if self.exploit_available:
            if self.vpr_score > 0.0:
                if self.vpr_score >= 7:
                    self.nessus_criticiality = 'High'
                elif self.vpr_score >= 4:
                    self.nessus_criticiality = 'Medium'
                else:
                    self.nessus_criticiality = 'Low'
            elif self.temporal_score > 0.0:
                if self.temporal_score >= 7:
                    self.nessus_criticiality = 'High'
                elif self.temporal_score >= 4:
                    self.nessus_criticiality = 'Medium'
                else:
                    self.nessus_criticiality = 'Low'
            elif self.cvss_score > 0.0:
                if self.cvss_score >= 7:
                    self.nessus_criticiality = 'High'
                elif self.cvss_score >= 4:
                    self.nessus_criticiality = 'Medium'
                else:
                    self.nessus_criticiality = 'Low'
        else:
            if self.vpr_score > 0.0:
                if self.vpr_score >= 7:
                    self.nessus_criticiality = 'Medium'
                elif self.vpr_score >= 4:
                    self.nessus_criticiality = 'Medium'
                else:
                    self.nessus_criticiality = 'Low'
            elif self.temporal_score > 0.0:
                if self.temporal_score >= 7:
                    self.nessus_criticiality = 'Medium'
                elif self.temporal_score >= 4:
                    self.nessus_criticiality = 'Medium'
                else:
                    self.nessus_criticiality = 'Low'
            elif self.cvss_score > 0.0:
                if self.cvss_score >= 7:
                    self.nessus_criticiality = 'Medium'
                elif self.cvss_score >= 4:
                    self.nessus_criticiality = 'Medium'
                else:
                    self.nessus_criticiality = 'Low'

    def get_host_risk(self):
        """
        Use a combination of host dns (self.dns) and the zone that host is in to define host risk

        For example:
        haproxy_box = re.search('.*haproxy.*', self.dns, flags=re.IGNORECASE)
        web_box = re.search('.*web.*', self.dns, flags=re.IGNORECASE)
        app_box = re.search('.*app.*', self.dns, flags=re.IGNORECASE)
        proxy_box = re.search('^proxy.*', self.dns, flags=re.IGNORECASE)

        if self.zone == 'DMZ':
            if self.platform == 'Linux':
                if web_box or haproxy_box:
                    self.host_risk = 'High'
                elif app_box:
                    self.host_risk = 'Medium'

        elif self.zone == 'Secure':
            if self.platform == 'Linux':
                if app_box:
                    self.host_risk = 'High'
                elif proxy_box:
                    self.host_risk = 'Medium'
        """

    def actual_criticality_insight(self):
        if self.host_risk == 'High':
            if self.nessus_criticiality == 'Low':
                self.actual_criticality = 'Medium'
            elif self.nessus_criticiality == 'Medium':
                self.actual_criticality = 'High'
            elif self.nessus_criticiality == 'High':
                self.actual_criticality = 'High'
        elif self.host_risk == 'Medium':
            if self.nessus_criticiality == 'Low':
                self.actual_criticality = 'Medium'
            elif self.nessus_criticiality == 'Medium':
                self.actual_criticality = 'Medium'
            elif self.nessus_criticiality == 'High':
                self.actual_criticality = 'High'
        elif self.host_risk == 'Low':
            if self.nessus_criticiality == 'Low':
                self.actual_criticality = 'Low'
            elif self.nessus_criticiality == 'Medium':
                self.actual_criticality = 'Low'
            elif self.nessus_criticiality == 'High':
                self.actual_criticality = 'Medium'
        else:
            self.actual_criticality = 'Unknown'


# Initiate download of all vulnerable assets
def initiate_download_vulnerabilities(tag: str) -> str:
    logger.info("Initiating download of %s vulnerabilities seen in the last 15 days" % tag)
    uuid = None
    headers = {'X-ApiKeys': 'accessKey=%s; secretKey=%s' % (tenable_client_id, tenable_secret_id),
               'Content-Type': 'application/json'}
    session = session_generator()
    data = {
        "num_assets": 1000,
        "filters": {
            "severity": ["low", "medium", "high", "critical"],
            "since": int((datetime.datetime.now() - datetime.timedelta(days=15)).strftime("%s")),
            "tag.Source": [tag]
        }
    }

    resp = session.post("%s/vulns/export" % tenable_api, headers=headers, json=data)
    response = resp.json()
    if resp.ok:
        uuid = response['export_uuid']
    elif resp.status_code == 429:
        logger.warning("Exceed rate limit.")
        time.sleep(60)
        # TO DO:
        # Check header to see if spits out retry.
        # print(resp.header)
        uuid = initiate_download_vulnerabilities(tag)
    else:
        logger.error('ERROR %s: %s' % (resp.status_code, resp.text))
        logger.error('Unable to make rest call to initiate download all %s vulnerabilities' % tag)
    return uuid


# Check if report is ready for download
def check_vulnerabilities_download_status(uuid: str) -> Tuple[str,List[int]]:
    logger.info("Checking download status of vulnerabilities for file %s" % uuid)
    headers = {'X-ApiKeys': 'accessKey=%s; secretKey=%s' % (tenable_client_id, tenable_secret_id),
               'Content-Type': 'application/json'}
    session = session_generator()
    status = None
    chunks = []
    resp = session.get("%s/vulns/export/%s/status" % (tenable_api, uuid), headers=headers)
    if resp.ok:
        response = resp.json()
        status = response['status']
        if status == 'FINISHED':
            chunks.extend(response['chunks_available'])

    elif resp.status_code == 429:
        logger.warning("Exceed rate limit.")
        time.sleep(60)
        # TO DO:
        # Check header to see if spits out retry.
        # print(resp.header)
        status, chunks = check_vulnerabilities_download_status(uuid)
    else:
        logger.error('ERROR %s: %s' % (resp.status_code, resp.text))
        logger.error('Unable to make rest call to get status of file download %s' % uuid)
    return status, chunks


def parse_vulnerabilities(vulnerability: Dict) -> TenableVulnerability:
    if 'exploit_available' in vulnerability['plugin'] and vulnerability['plugin']['exploit_available']:
        exploit_available = True
    else:
        exploit_available = False

    if 'cvss3_temporal_score' in vulnerability['plugin']:
        temporal_score = vulnerability['plugin']['cvss3_temporal_score']
    elif 'cvss_temporal_score' in vulnerability['plugin']:
        temporal_score = vulnerability['plugin']['cvss_temporal_score']
    else:
        temporal_score = 0.0

    if 'cvss3_base_score' in vulnerability['plugin']:
        base_score = vulnerability['plugin']['cvss3_base_score']
    elif 'cvss_base_score' in vulnerability['plugin']:
        base_score = vulnerability['plugin']['cvss_base_score']
    else:
        base_score = 0.0

    if 'vpr' in vulnerability['plugin']:
        if 'score' in vulnerability['plugin']['vpr']:
            vpr = vulnerability['plugin']['vpr']['score']
        else:
            vpr = 0.0
    else:
        vpr = 0.0

    if 'see_also' in vulnerability['plugin']:
        additional_links = [vulnerability['plugin']['see_also'][0]]
    else:
        additional_links = []

    if 'cve' in vulnerability['plugin']:
        cves = vulnerability['plugin']['cve']
    else:
        cves = []

    vulnobj = TenableVulnerability(
        vulnerability['plugin']['name'],
        vulnerability['plugin']['solution'].replace('\r', '').replace('\n', ' '),
        additional_links,
        vulnerability['asset']['ipv4'],
        vulnerability['asset']['fqdn'] or vulnerability['asset']['hostname'],
        vulnerability['asset']['operating_system'][0] or '',
        cves,
        vulnerability['plugin']['family'],
        exploit_available,
        base_score,
        temporal_score,
        vpr
    )

    return vulnobj


# Get vulnerability of only those whose agents were last seen in 30 days
def download_vulnerabilities(uuid: str, chunk_id: int, agents: List[str]) -> List[TenableVulnerability]:
    vulnerabilities = []
    logger.info("Fetching list of vulnerabilities for chunk %d" % chunk_id)
    headers = {'X-ApiKeys': 'accessKey=%s; secretKey=%s' % (tenable_client_id, tenable_secret_id),
               'Content-Type': 'application/json'}
    session = session_generator()
    resp = session.get("%s/vulns/export/%s/chunks/%d" % (tenable_api, uuid, chunk_id), headers=headers)
    if resp.ok:
        response = resp.json()
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
            fs = [executor.submit(parse_vulnerabilities, vulnerability) for vulnerability in response if (agents and 'agent_uuid' in vulnerability['asset'] and vulnerability['asset']['agent_uuid'] in agents) or not agents]
            for future in concurrent.futures.as_completed(fs):
                vulnerabilities.append(future.result())
    elif resp.status_code == 429:
        logger.warning("Exceed rate limit.")
        time.sleep(60)
        # TO DO:
        # Check header to see if spits out retry.
        # print(resp.header)
        vulnerabilities = download_vulnerabilities(uuid, chunk_id, agents)
    else:
        logger.error('ERROR %s: %s' % (resp.status_code, resp.text))
        logger.error('Unable to make rest call to download vulnerabilities for chunk %d' % chunk_id)
    return vulnerabilities


# Get any scanner id as all devices agents are associated with all scanners
def get_any_scanner_id() -> int:
    headers = {'X-ApiKeys': 'accessKey=%s; secretKey=%s' % (tenable_client_id, tenable_secret_id),
               'Content-Type': 'application/json'}
    session = session_generator()
    r = session.get("%s/scanners" % tenable_api, headers=headers)
    if r.ok:
        response = r.json()
        scanner_id = response['scanners'][0]['id']
        logger.info("Received Tenable Scanner ID")
        return scanner_id
    else:
        logger.error('Unable to make rest call to get scanner id')
        logger.error('ERROR %s: %s' % (r.status_code, r.text))
        return 0


# Fetch the groups (id and text) associated with the scanner
def get_agent_groups(scanner_id: int) -> Dict[int, str]:
    logger.info("Fetching all agent groups...")
    agent_group_ids = {}
    headers = {'X-ApiKeys': 'accessKey=%s; secretKey=%s' % (tenable_client_id, tenable_secret_id),
               'Content-Type': 'application/json'}
    session = session_generator()
    agent_group_request = session.get("%s/scanners/%d/agent-groups" % (tenable_api, scanner_id), headers=headers)
    if agent_group_request.ok:
        agent_group_response = agent_group_request.json()
        for agent_group in agent_group_response['groups']:
            agent_group_ids[agent_group['id']] = agent_group['name']
        logger.info("Completed collecting all agent groups")
    return agent_group_ids


# Fetches all agents in a particular agent group
def get_agents_in_agent_group(scanner_id: int, group_id: int) -> List[str]:
    agents = []
    offset = 0
    session = session_generator()
    logger.info("Getting all agents belonging to group id %d", group_id)
    while True:
        headers = {'X-ApiKeys': 'accessKey=%s; secretKey=%s' % (tenable_client_id, tenable_secret_id),
                   'Content-Type': 'application/json'}
        agent_request = session.get(
            "%s/scanners/%d/agent-groups/%s?limit=5000&offset=%d" % (tenable_api, scanner_id, group_id, offset),
            headers=headers)
        if agent_request.ok:
            agent_response = agent_request.json()
            for agent in agent_response['agents']:
                if 'last_scanned' in agent and agent['last_scanned'] and agent['last_scanned'] >= int((datetime.datetime.now() - datetime.timedelta(days=30)).strftime("%s")):
                    agents.append(agent['uuid'].replace('-', ''))

            # Tackle pagination
            if agent_response['pagination']['total'] - offset <= 5000:
                break
            else:
                offset = offset + 5000
        else:
            logger.error('Error %d:%s', agent_request.status_code, agent_request.text)
    return agents


# Fetch all gcp agents
def get_gcp_agents(scanner_id: int) -> List[str]:
    '''
    Fetch Agents from Groups for GCP based on Agent Group Name
    '''
    agents = []
    logger.info("Getting all gcp servers")
    agent_group_ids = get_agent_groups(scanner_id)
    if agent_group_ids:
        # Map based on the value to the group id and fetch agents accordingly
        for group_id in agent_group_ids:
            if 'GCP' in agent_group_ids[group_id]:
                agents.extend(get_agents_in_agent_group(scanner_id, group_id))
            else:
                pass
    agents = list(set(agents))
    logger.info('Found %d gcp agents' % len(agents))
    return agents


# Fetch all workstation agents
def get_workstation_agents(scanner_id:int) -> List[str]:
    '''
        Fetch Agents from Groups for Workstations based on Agent Group Name
    '''
    agents = []
    logger.info("Getting all workstation agents")
    agent_group_ids = get_agent_groups(scanner_id)
    if agent_group_ids:
        # Map based on the value to the group id and fetch agents accordingly
        for group_id in agent_group_ids:
            if 'Workstations' in agent_group_ids[group_id]:
                agents.extend(get_agents_in_agent_group(scanner_id, group_id))
            else:
                pass
    agents = list(set(agents))
    logger.info('Found %d workstation agents' % len(agents))
    return agents


def get_rerouted_url(link):
    link_dict = {}
    resp = requests.get(link)
    link_dict[link] = resp.url
    return link_dict


def mapping_security_zone(iplist: List[str]) -> Dict[str, str]:
    """
    Fake list of ranges for GCP
    """
    dmz_range = list(netaddr.IPNetwork('192.168.0.0/24'))
    secure_range = list(netaddr.IPNetwork('192.168.2.0/22'))

    ip_zone = {}

    for ip in iplist:
        if netaddr.IPAddress(ip) in dmz_range:
            ip_zone[ip] = 'DMZ'
        elif netaddr.IPAddress(ip) in secure_range:
            ip_zone[ip] = 'Secure'
    return ip_zone


def fetch_gcp_vulnerabilities() -> List[TenableVulnerability]:
    agents = []
    vulnerabilities = []
    uuid = initiate_download_vulnerabilities(tenable_gcp_tag)
    if uuid is not None:
        status, chunks = check_vulnerabilities_download_status(uuid)
        while status != 'FINISHED':
            time.sleep(10)
            status, chunks = check_vulnerabilities_download_status(uuid)
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
            fs = [executor.submit(download_vulnerabilities, uuid, chunk_id, agents) for chunk_id in chunks]
            for future in concurrent.futures.as_completed(fs):
                if future.result() is not None:
                    vulnerabilities.extend(future.result())

    logger.info('Mapping info links to rerouted link')
    links = []
    for vulnerability in vulnerabilities:
        links.extend(vulnerability.additional_links)
    links = list(set(links))
    map_link_to_its_rerouted_url = {}

    with concurrent.futures.ThreadPoolExecutor(max_workers=1000) as executor:
        for link_dict in executor.map(get_rerouted_url, links):
            map_link_to_its_rerouted_url.update(link_dict)

    for vulnerability in vulnerabilities:
        temp_links_holder = []
        for link in vulnerability.additional_links:
            if link in map_link_to_its_rerouted_url:
                temp_links_holder.append(map_link_to_its_rerouted_url[link])
        vulnerability.additional_links = temp_links_holder

    # Map zones to IPs
    vulnerable_ips = list(set(vulnerability.ip for vulnerability in vulnerabilities))
    logging.info('Mapping security zone to %d IPs' % len(vulnerable_ips))
    ip_zone_mapping = mapping_security_zone(vulnerable_ips)
    for vulnerability in vulnerabilities:
        if vulnerability.ip in ip_zone_mapping:
            vulnerability.zone = ip_zone_mapping[vulnerability.ip]

    logger.info("Found %d IPs that are not tagged to zones" % len(set([vulnerability.ip for vulnerability in vulnerabilities if not vulnerability.zone])))

    for vulnerability in vulnerabilities:
        vulnerability.get_host_risk()

    logging.info('Getting actual criticality of the vulnerabilities')
    for vulnerability in vulnerabilities:
        vulnerability.actual_criticality_insight()

    logger.info('Found %d vulnerabilities for GCP' % len(vulnerabilities))
    return vulnerabilities


def fetch_workstation_vulnerabilities() -> List[TenableVulnerability]:
    vulnerabilities = []
    scanner_id = get_any_scanner_id()
    if scanner_id > 0:
        agents = get_workstation_agents(scanner_id)
        uuid = initiate_download_vulnerabilities(tenable_workstations_tag)
        if uuid is not None and agents:
            status, chunks = check_vulnerabilities_download_status(uuid)
            while status != 'FINISHED':
                time.sleep(10)
                status, chunks = check_vulnerabilities_download_status(uuid)

            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
                fs = [executor.submit(download_vulnerabilities, uuid, chunk_id, agents) for chunk_id in chunks]
                for future in concurrent.futures.as_completed(fs):
                    if future.result():
                        vulnerabilities.extend(future.result())

    logger.info('Mapping info links to rerouted link')
    links = []
    for vulnerability in vulnerabilities:
        links.extend(vulnerability.additional_links)
    links = list(set(links))
    map_link_to_its_rerouted_url = {}

    with concurrent.futures.ThreadPoolExecutor(max_workers=1000) as executor:
        for link_dict in executor.map(get_rerouted_url, links):
            map_link_to_its_rerouted_url.update(link_dict)

    for vulnerability in vulnerabilities:
        temp_links_holder = []
        for link in vulnerability.additional_links:
            if link in map_link_to_its_rerouted_url:
                temp_links_holder.append(map_link_to_its_rerouted_url[link])
        vulnerability.additional_links = temp_links_holder

    for vulnerability in vulnerabilities:
        vulnerability.actual_criticality_insight()

    logger.info('Found %d vulnerabilities for workstations' % len(vulnerabilities))
    return vulnerabilities
